# -*- coding: utf-8 -*-
"""Alexnet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WXzb9L2VblKe8hddzDa3PHD3pSB3T_HD
"""

import tensorflow as tf

tf.__version__

import tensorflow.keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization

#1st convolutional layer
model = Sequential()
model.add(Conv2D(filters=96, input_shape=(227,227,3), kernel_size=(11,11), strides=(4,4), padding='valid'))
model.add(Activation('relu'))
#pooling
model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))
#Batchnormalazation befor passining it to the next layer
model.add(BatchNormalization())

#2nd Convolutional layer
model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))
model.add(Activation('relu'))
#pooling
model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))
#Batchnormalazation 
model.add(BatchNormalization())

#3rd Convolutinal layer
model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))
model.add(Activation('relu'))
#Batch Normalization
model.add(BatchNormalization())

#4th Convolutional layer
model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))
model.add(Activation('relu'))
#Batch Normalazation
model.add(BatchNormalization())

#5th Convolutional layer
model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))
model.add(Activation('relu'))
#pooling
model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))
#Batchnormalazation
model.add(BatchNormalization())

#passing it to a Dense Layer
model.add(Flatten())
#1st Dense Layer
model.add(Dense(4096, input_shape=(224*224*3,)))
model.add(Activation('relu'))
#Add Droupout to prevent overfitting
model.add(Dropout(0.4))
#Batch Normalazation
model.add(BatchNormalization())

#2nd Dense Layer
model.add(Dense(4096))
model.add(Activation('relu'))
model.add(Dropout(0.4))
model.add(BatchNormalization())

#3rd Dense Layer
model.add(Dense(1000))
model.add(Activation('relu'))
model.add(Dropout(0.4))
model.add(BatchNormalization())

#Output Layer
model.add(Dense(17))
model.add(Activation('softmax'))

model.summary()

